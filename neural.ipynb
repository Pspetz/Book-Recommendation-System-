{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /home/spetz/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to /home/spetz/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from elasticsearch import Elasticsearch\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "import keras\n",
    "import re\n",
    "import multiprocessing\n",
    "nltk.download('punkt')\n",
    "from nltk.tokenize import word_tokenize\n",
    "from elasticsearch import Elasticsearch\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "from gensim.models import word2vec\n",
    "from keras import losses\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Softmax\n",
    "from sklearn.model_selection import train_test_split\n",
    "from numpy import array\n",
    "from numpy import asarray\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from numpy import zeros\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.snowball import SnowballStemmer # Used for stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>uid</th>\n",
       "      <th>location</th>\n",
       "      <th>age</th>\n",
       "      <th>isbn</th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_author</th>\n",
       "      <th>summary</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>weston, ,</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0375759778</td>\n",
       "      <td>Prague : A Novel</td>\n",
       "      <td>ARTHUR PHILLIPS</td>\n",
       "      <td>Five American expatriates living in Budapest i...</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>51</td>\n",
       "      <td>renton, washington, usa</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0440225701</td>\n",
       "      <td>The Street Lawyer</td>\n",
       "      <td>JOHN GRISHAM</td>\n",
       "      <td>After a violent encounter with a homeless man,...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>75</td>\n",
       "      <td>long beach, california, usa</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1558531025</td>\n",
       "      <td>Life's Little Instruction Book (Life's Little ...</td>\n",
       "      <td>H. Jackson Brown</td>\n",
       "      <td>A collection of advice on how to live a happy ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>125</td>\n",
       "      <td>lansing, michigan, usa</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0679429220</td>\n",
       "      <td>Midnight in the Garden of Good and Evil: A Sav...</td>\n",
       "      <td>John Berendt</td>\n",
       "      <td>In charming, beautiful, and wealthy old-South ...</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>178</td>\n",
       "      <td>rexford, new york, usa</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0451410319</td>\n",
       "      <td>Hush</td>\n",
       "      <td>Anne Frasier</td>\n",
       "      <td>Sixteen years after her own son fell victim to...</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22575</th>\n",
       "      <td>1</td>\n",
       "      <td>278542</td>\n",
       "      <td>greeneville, tennessee, usa</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0446605409</td>\n",
       "      <td>Plum Island</td>\n",
       "      <td>Nelson DeMille</td>\n",
       "      <td>Fast-paced and atmospheric, marked by entranci...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22576</th>\n",
       "      <td>1</td>\n",
       "      <td>278692</td>\n",
       "      <td>butler, western australia, australia</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0060976845</td>\n",
       "      <td>Little Altars Everywhere: A Novel</td>\n",
       "      <td>Rebecca Wells</td>\n",
       "      <td>Don&amp;#39;t miss Little Altars Everywhere, the N...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22577</th>\n",
       "      <td>1</td>\n",
       "      <td>278849</td>\n",
       "      <td>georgetown, ontario, canada</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0445210214</td>\n",
       "      <td>Mythology 101 (Questar Fantasy)</td>\n",
       "      <td>Jody Lynn Nye</td>\n",
       "      <td>Keith Doyle is determined in his campaign to t...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22578</th>\n",
       "      <td>1</td>\n",
       "      <td>278849</td>\n",
       "      <td>georgetown, ontario, canada</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0771012837</td>\n",
       "      <td>Klondike: The Last Great Gold Rush, 1896-1899</td>\n",
       "      <td>Pierre Berton</td>\n",
       "      <td>The Klondike stampede was a wild interlude in ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22579</th>\n",
       "      <td>1</td>\n",
       "      <td>278849</td>\n",
       "      <td>georgetown, ontario, canada</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0920656307</td>\n",
       "      <td>Secret of Willow Castle</td>\n",
       "      <td>Ly Cook</td>\n",
       "      <td>Canadian story early 19th century Orphaned ser...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>22580 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cluster     uid                              location   age  \\\n",
       "0            0      19                             weston, ,  14.0   \n",
       "1            0      51               renton, washington, usa  34.0   \n",
       "2            0      75           long beach, california, usa  37.0   \n",
       "3            0     125                lansing, michigan, usa  49.0   \n",
       "4            0     178                rexford, new york, usa  28.0   \n",
       "...        ...     ...                                   ...   ...   \n",
       "22575        1  278542           greeneville, tennessee, usa  39.0   \n",
       "22576        1  278692  butler, western australia, australia  26.0   \n",
       "22577        1  278849           georgetown, ontario, canada  23.0   \n",
       "22578        1  278849           georgetown, ontario, canada  23.0   \n",
       "22579        1  278849           georgetown, ontario, canada  23.0   \n",
       "\n",
       "             isbn                                         book_title  \\\n",
       "0      0375759778                                   Prague : A Novel   \n",
       "1      0440225701                                  The Street Lawyer   \n",
       "2      1558531025  Life's Little Instruction Book (Life's Little ...   \n",
       "3      0679429220  Midnight in the Garden of Good and Evil: A Sav...   \n",
       "4      0451410319                                               Hush   \n",
       "...           ...                                                ...   \n",
       "22575  0446605409                                        Plum Island   \n",
       "22576  0060976845                  Little Altars Everywhere: A Novel   \n",
       "22577  0445210214                    Mythology 101 (Questar Fantasy)   \n",
       "22578  0771012837      Klondike: The Last Great Gold Rush, 1896-1899   \n",
       "22579  0920656307                            Secret of Willow Castle   \n",
       "\n",
       "            book_author                                            summary  \\\n",
       "0       ARTHUR PHILLIPS  Five American expatriates living in Budapest i...   \n",
       "1          JOHN GRISHAM  After a violent encounter with a homeless man,...   \n",
       "2      H. Jackson Brown  A collection of advice on how to live a happy ...   \n",
       "3          John Berendt  In charming, beautiful, and wealthy old-South ...   \n",
       "4          Anne Frasier  Sixteen years after her own son fell victim to...   \n",
       "...                 ...                                                ...   \n",
       "22575    Nelson DeMille  Fast-paced and atmospheric, marked by entranci...   \n",
       "22576     Rebecca Wells  Don&#39;t miss Little Altars Everywhere, the N...   \n",
       "22577     Jody Lynn Nye  Keith Doyle is determined in his campaign to t...   \n",
       "22578     Pierre Berton  The Klondike stampede was a wild interlude in ...   \n",
       "22579           Ly Cook  Canadian story early 19th century Orphaned ser...   \n",
       "\n",
       "       rating  \n",
       "0           7  \n",
       "1           9  \n",
       "2           5  \n",
       "3          10  \n",
       "4           6  \n",
       "...       ...  \n",
       "22575       0  \n",
       "22576       3  \n",
       "22577       0  \n",
       "22578       0  \n",
       "22579       0  \n",
       "\n",
       "[22580 rows x 9 columns]"
      ]
     },
     "execution_count": 186,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv  = pd.read_csv(\"final_cluster.csv\")\n",
    "csv = csv[['cluster' , 'uid' ,'location','age' , 'isbn' ,'book_title' ,'book_author','summary','rating']]\n",
    "\n",
    "csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>uid</th>\n",
       "      <th>location</th>\n",
       "      <th>age</th>\n",
       "      <th>isbn</th>\n",
       "      <th>book_title</th>\n",
       "      <th>book_author</th>\n",
       "      <th>summary</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>weston, ,</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0375759778</td>\n",
       "      <td>Prague : A Novel</td>\n",
       "      <td>ARTHUR PHILLIPS</td>\n",
       "      <td>Five American expatriates living in Budapest i...</td>\n",
       "      <td>7.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>renton, washington, usa</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0440225701</td>\n",
       "      <td>The Street Lawyer</td>\n",
       "      <td>JOHN GRISHAM</td>\n",
       "      <td>After a violent encounter with a homeless man,...</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>long beach, california, usa</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1558531025</td>\n",
       "      <td>Life's Little Instruction Book (Life's Little ...</td>\n",
       "      <td>H. Jackson Brown</td>\n",
       "      <td>A collection of advice on how to live a happy ...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>125.0</td>\n",
       "      <td>lansing, michigan, usa</td>\n",
       "      <td>49.0</td>\n",
       "      <td>0679429220</td>\n",
       "      <td>Midnight in the Garden of Good and Evil: A Sav...</td>\n",
       "      <td>John Berendt</td>\n",
       "      <td>In charming, beautiful, and wealthy old-South ...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>178.0</td>\n",
       "      <td>rexford, new york, usa</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0451410319</td>\n",
       "      <td>Hush</td>\n",
       "      <td>Anne Frasier</td>\n",
       "      <td>Sixteen years after her own son fell victim to...</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22568</th>\n",
       "      <td>1.0</td>\n",
       "      <td>278096.0</td>\n",
       "      <td>belle isle, florida, usa</td>\n",
       "      <td>57.0</td>\n",
       "      <td>0440236053</td>\n",
       "      <td>Writ of Execution</td>\n",
       "      <td>Perri O'Shaughnessy</td>\n",
       "      <td>Nina Reilly takes on the case of Jessie Potter...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22569</th>\n",
       "      <td>1.0</td>\n",
       "      <td>278212.0</td>\n",
       "      <td>chicago, illinois, usa</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0688170528</td>\n",
       "      <td>The Pact: A Love Story</td>\n",
       "      <td>Jodi Picoult</td>\n",
       "      <td>It&amp;#39;s rare to find a writer who combines Al...</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22571</th>\n",
       "      <td>1.0</td>\n",
       "      <td>278373.0</td>\n",
       "      <td>dubbo, new south wales, australia</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0971880107</td>\n",
       "      <td>Wild Animus</td>\n",
       "      <td>Rich Shapero</td>\n",
       "      <td>Wild animus is a search for the primordial, a ...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22572</th>\n",
       "      <td>1.0</td>\n",
       "      <td>278431.0</td>\n",
       "      <td>alexandria, virginia, usa</td>\n",
       "      <td>39.0</td>\n",
       "      <td>0446608262</td>\n",
       "      <td>The Lion's Game</td>\n",
       "      <td>Nelson DeMille</td>\n",
       "      <td>Filled with unrelenting suspense and surprisin...</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22576</th>\n",
       "      <td>1.0</td>\n",
       "      <td>278692.0</td>\n",
       "      <td>butler, western australia, australia</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0060976845</td>\n",
       "      <td>Little Altars Everywhere: A Novel</td>\n",
       "      <td>Rebecca Wells</td>\n",
       "      <td>Don&amp;#39;t miss Little Altars Everywhere, the N...</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17410 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cluster       uid                              location   age  \\\n",
       "0          0.0      19.0                             weston, ,  14.0   \n",
       "1          0.0      51.0               renton, washington, usa  34.0   \n",
       "2          0.0      75.0           long beach, california, usa  37.0   \n",
       "3          0.0     125.0                lansing, michigan, usa  49.0   \n",
       "4          0.0     178.0                rexford, new york, usa  28.0   \n",
       "...        ...       ...                                   ...   ...   \n",
       "22568      1.0  278096.0              belle isle, florida, usa  57.0   \n",
       "22569      1.0  278212.0                chicago, illinois, usa  33.0   \n",
       "22571      1.0  278373.0     dubbo, new south wales, australia  13.0   \n",
       "22572      1.0  278431.0             alexandria, virginia, usa  39.0   \n",
       "22576      1.0  278692.0  butler, western australia, australia  26.0   \n",
       "\n",
       "             isbn                                         book_title  \\\n",
       "0      0375759778                                   Prague : A Novel   \n",
       "1      0440225701                                  The Street Lawyer   \n",
       "2      1558531025  Life's Little Instruction Book (Life's Little ...   \n",
       "3      0679429220  Midnight in the Garden of Good and Evil: A Sav...   \n",
       "4      0451410319                                               Hush   \n",
       "...           ...                                                ...   \n",
       "22568  0440236053                                  Writ of Execution   \n",
       "22569  0688170528                             The Pact: A Love Story   \n",
       "22571  0971880107                                        Wild Animus   \n",
       "22572  0446608262                                    The Lion's Game   \n",
       "22576  0060976845                  Little Altars Everywhere: A Novel   \n",
       "\n",
       "               book_author                                            summary  \\\n",
       "0          ARTHUR PHILLIPS  Five American expatriates living in Budapest i...   \n",
       "1             JOHN GRISHAM  After a violent encounter with a homeless man,...   \n",
       "2         H. Jackson Brown  A collection of advice on how to live a happy ...   \n",
       "3             John Berendt  In charming, beautiful, and wealthy old-South ...   \n",
       "4             Anne Frasier  Sixteen years after her own son fell victim to...   \n",
       "...                    ...                                                ...   \n",
       "22568  Perri O'Shaughnessy  Nina Reilly takes on the case of Jessie Potter...   \n",
       "22569         Jodi Picoult  It&#39;s rare to find a writer who combines Al...   \n",
       "22571         Rich Shapero  Wild animus is a search for the primordial, a ...   \n",
       "22572       Nelson DeMille  Filled with unrelenting suspense and surprisin...   \n",
       "22576        Rebecca Wells  Don&#39;t miss Little Altars Everywhere, the N...   \n",
       "\n",
       "       rating  \n",
       "0         7.0  \n",
       "1         9.0  \n",
       "2         5.0  \n",
       "3        10.0  \n",
       "4         6.0  \n",
       "...       ...  \n",
       "22568     2.0  \n",
       "22569     5.0  \n",
       "22571     1.0  \n",
       "22572     2.0  \n",
       "22576     3.0  \n",
       "\n",
       "[17410 rows x 9 columns]"
      ]
     },
     "execution_count": 187,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Delete all the rows from dataframe which have rating = 0\n",
    "cluster = csv.where(csv['rating'] != 0).dropna()\n",
    "#cluster1_new = csv_cluster1.where(csv_cluster1['rating'] != 0).dropna()\n",
    "cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>isbn</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0002005395</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0002214067</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0002237857</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0002251760</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0002253402</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8930</th>\n",
       "      <td>9171492674</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8931</th>\n",
       "      <td>9507399097</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8932</th>\n",
       "      <td>9628606727</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8933</th>\n",
       "      <td>9722107909</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8934</th>\n",
       "      <td>9999999999</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8935 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            isbn  rating\n",
       "0     0002005395     8.0\n",
       "1     0002214067    10.0\n",
       "2     0002237857     4.0\n",
       "3     0002251760     9.0\n",
       "4     0002253402     6.0\n",
       "...          ...     ...\n",
       "8930  9171492674    10.0\n",
       "8931  9507399097    10.0\n",
       "8932  9628606727    10.0\n",
       "8933  9722107909     8.0\n",
       "8934  9999999999     5.0\n",
       "\n",
       "[8935 rows x 2 columns]"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "avg_rating = cluster.groupby(['isbn'])['rating'].mean().reset_index(name='rating')\n",
    "#avg_rating1 = cluster1_new.groupby(['isbn'])['rating'].mean().reset_index(name='rating')\n",
    "\n",
    "avg_rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>summary</th>\n",
       "      <th>uid</th>\n",
       "      <th>rating</th>\n",
       "      <th>isbn</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Five American expatriates living in Budapest i...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0375759778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>After a violent encounter with a homeless man,...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0440225701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>A collection of advice on how to live a happy ...</td>\n",
       "      <td>75.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1558531025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>In charming, beautiful, and wealthy old-South ...</td>\n",
       "      <td>125.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0679429220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Sixteen years after her own son fell victim to...</td>\n",
       "      <td>178.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0451410319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22568</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Nina Reilly takes on the case of Jessie Potter...</td>\n",
       "      <td>278096.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0440236053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22569</th>\n",
       "      <td>1.0</td>\n",
       "      <td>It&amp;#39;s rare to find a writer who combines Al...</td>\n",
       "      <td>278212.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0688170528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22571</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Wild animus is a search for the primordial, a ...</td>\n",
       "      <td>278373.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0971880107</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22572</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Filled with unrelenting suspense and surprisin...</td>\n",
       "      <td>278431.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0446608262</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22576</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Don&amp;#39;t miss Little Altars Everywhere, the N...</td>\n",
       "      <td>278692.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0060976845</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17410 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cluster                                            summary       uid  \\\n",
       "0          0.0  Five American expatriates living in Budapest i...      19.0   \n",
       "1          0.0  After a violent encounter with a homeless man,...      51.0   \n",
       "2          0.0  A collection of advice on how to live a happy ...      75.0   \n",
       "3          0.0  In charming, beautiful, and wealthy old-South ...     125.0   \n",
       "4          0.0  Sixteen years after her own son fell victim to...     178.0   \n",
       "...        ...                                                ...       ...   \n",
       "22568      1.0  Nina Reilly takes on the case of Jessie Potter...  278096.0   \n",
       "22569      1.0  It&#39;s rare to find a writer who combines Al...  278212.0   \n",
       "22571      1.0  Wild animus is a search for the primordial, a ...  278373.0   \n",
       "22572      1.0  Filled with unrelenting suspense and surprisin...  278431.0   \n",
       "22576      1.0  Don&#39;t miss Little Altars Everywhere, the N...  278692.0   \n",
       "\n",
       "       rating        isbn  \n",
       "0         7.0  0375759778  \n",
       "1         9.0  0440225701  \n",
       "2         5.0  1558531025  \n",
       "3        10.0  0679429220  \n",
       "4         6.0  0451410319  \n",
       "...       ...         ...  \n",
       "22568     2.0  0440236053  \n",
       "22569     5.0  0688170528  \n",
       "22571     1.0  0971880107  \n",
       "22572     2.0  0446608262  \n",
       "22576     3.0  0060976845  \n",
       "\n",
       "[17410 rows x 5 columns]"
      ]
     },
     "execution_count": 189,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create user rating dataframe ,whice contains all info about each movie rating\n",
    "new_df = cluster[['cluster','summary','uid','rating','isbn']]\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2743/2028500723.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['Clean'] = new_df['summary'].apply(clean_data)\n"
     ]
    }
   ],
   "source": [
    "# Text-cleaning function\n",
    "def clean_data(csv):\n",
    "    #remove with regex all punctuation\n",
    "    text = re.sub('[^A-Za-z0-9]+', ' ', csv)\n",
    "    #lowercase\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "\n",
    "new_df['Clean'] = new_df['summary'].apply(clean_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2743/810779629.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['removestopwords'] = new_df['Clean'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>summary</th>\n",
       "      <th>uid</th>\n",
       "      <th>rating</th>\n",
       "      <th>isbn</th>\n",
       "      <th>Clean</th>\n",
       "      <th>removestopwords</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Five American expatriates living in Budapest i...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0375759778</td>\n",
       "      <td>five american expatriates living in budapest i...</td>\n",
       "      <td>five american expatriates living budapest earl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>After a violent encounter with a homeless man,...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0440225701</td>\n",
       "      <td>after a violent encounter with a homeless man ...</td>\n",
       "      <td>violent encounter homeless man talented corpor...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>A collection of advice on how to live a happy ...</td>\n",
       "      <td>75.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1558531025</td>\n",
       "      <td>a collection of advice on how to live a happy ...</td>\n",
       "      <td>collection advice live happy rewarding life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>In charming, beautiful, and wealthy old-South ...</td>\n",
       "      <td>125.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0679429220</td>\n",
       "      <td>in charming beautiful and wealthy old south sa...</td>\n",
       "      <td>charming beautiful wealthy old south savannah ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Sixteen years after her own son fell victim to...</td>\n",
       "      <td>178.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0451410319</td>\n",
       "      <td>sixteen years after her own son fell victim to...</td>\n",
       "      <td>sixteen years son fell victim serial killer cr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22568</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Nina Reilly takes on the case of Jessie Potter...</td>\n",
       "      <td>278096.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0440236053</td>\n",
       "      <td>nina reilly takes on the case of jessie potter...</td>\n",
       "      <td>nina reilly takes case jessie potter desperate...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22569</th>\n",
       "      <td>1.0</td>\n",
       "      <td>It&amp;#39;s rare to find a writer who combines Al...</td>\n",
       "      <td>278212.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0688170528</td>\n",
       "      <td>it 39 s rare to find a writer who combines ali...</td>\n",
       "      <td>39 rare find writer combines alice hoffman 39 ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22571</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Wild animus is a search for the primordial, a ...</td>\n",
       "      <td>278373.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0971880107</td>\n",
       "      <td>wild animus is a search for the primordial a t...</td>\n",
       "      <td>wild animus search primordial test human found...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22572</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Filled with unrelenting suspense and surprisin...</td>\n",
       "      <td>278431.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0446608262</td>\n",
       "      <td>filled with unrelenting suspense and surprisin...</td>\n",
       "      <td>filled unrelenting suspense surprising plot tw...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22576</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Don&amp;#39;t miss Little Altars Everywhere, the N...</td>\n",
       "      <td>278692.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0060976845</td>\n",
       "      <td>don 39 t miss little altars everywhere the new...</td>\n",
       "      <td>39 miss little altars everywhere new york time...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17410 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cluster                                            summary       uid  \\\n",
       "0          0.0  Five American expatriates living in Budapest i...      19.0   \n",
       "1          0.0  After a violent encounter with a homeless man,...      51.0   \n",
       "2          0.0  A collection of advice on how to live a happy ...      75.0   \n",
       "3          0.0  In charming, beautiful, and wealthy old-South ...     125.0   \n",
       "4          0.0  Sixteen years after her own son fell victim to...     178.0   \n",
       "...        ...                                                ...       ...   \n",
       "22568      1.0  Nina Reilly takes on the case of Jessie Potter...  278096.0   \n",
       "22569      1.0  It&#39;s rare to find a writer who combines Al...  278212.0   \n",
       "22571      1.0  Wild animus is a search for the primordial, a ...  278373.0   \n",
       "22572      1.0  Filled with unrelenting suspense and surprisin...  278431.0   \n",
       "22576      1.0  Don&#39;t miss Little Altars Everywhere, the N...  278692.0   \n",
       "\n",
       "       rating        isbn                                              Clean  \\\n",
       "0         7.0  0375759778  five american expatriates living in budapest i...   \n",
       "1         9.0  0440225701  after a violent encounter with a homeless man ...   \n",
       "2         5.0  1558531025  a collection of advice on how to live a happy ...   \n",
       "3        10.0  0679429220  in charming beautiful and wealthy old south sa...   \n",
       "4         6.0  0451410319  sixteen years after her own son fell victim to...   \n",
       "...       ...         ...                                                ...   \n",
       "22568     2.0  0440236053  nina reilly takes on the case of jessie potter...   \n",
       "22569     5.0  0688170528  it 39 s rare to find a writer who combines ali...   \n",
       "22571     1.0  0971880107  wild animus is a search for the primordial a t...   \n",
       "22572     2.0  0446608262  filled with unrelenting suspense and surprisin...   \n",
       "22576     3.0  0060976845  don 39 t miss little altars everywhere the new...   \n",
       "\n",
       "                                         removestopwords  \n",
       "0      five american expatriates living budapest earl...  \n",
       "1      violent encounter homeless man talented corpor...  \n",
       "2            collection advice live happy rewarding life  \n",
       "3      charming beautiful wealthy old south savannah ...  \n",
       "4      sixteen years son fell victim serial killer cr...  \n",
       "...                                                  ...  \n",
       "22568  nina reilly takes case jessie potter desperate...  \n",
       "22569  39 rare find writer combines alice hoffman 39 ...  \n",
       "22571  wild animus search primordial test human found...  \n",
       "22572  filled unrelenting suspense surprising plot tw...  \n",
       "22576  39 miss little altars everywhere new york time...  \n",
       "\n",
       "[17410 rows x 7 columns]"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "new_df['removestopwords'] = new_df['Clean'].apply(lambda x: ' '.join([word for word in x.split() if word not in (stop_words)]))\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_2743/611209206.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  new_df['Stemmed'] = new_df['removestopwords'].apply(lambda x: ' '.join([stemmer.stem(word) for word in str(x).split()]))\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cluster</th>\n",
       "      <th>summary</th>\n",
       "      <th>uid</th>\n",
       "      <th>rating</th>\n",
       "      <th>isbn</th>\n",
       "      <th>Stemmed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Five American expatriates living in Budapest i...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0375759778</td>\n",
       "      <td>five american expatri live budapest earli 1990...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>After a violent encounter with a homeless man,...</td>\n",
       "      <td>51.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0440225701</td>\n",
       "      <td>violent encount homeless man talent corpor law...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>A collection of advice on how to live a happy ...</td>\n",
       "      <td>75.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1558531025</td>\n",
       "      <td>collect advic live happi reward life</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>In charming, beautiful, and wealthy old-South ...</td>\n",
       "      <td>125.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0679429220</td>\n",
       "      <td>charm beauti wealthi old south savannah georgi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>Sixteen years after her own son fell victim to...</td>\n",
       "      <td>178.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0451410319</td>\n",
       "      <td>sixteen year son fell victim serial killer cri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22568</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Nina Reilly takes on the case of Jessie Potter...</td>\n",
       "      <td>278096.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0440236053</td>\n",
       "      <td>nina reilli take case jessi potter desper youn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22569</th>\n",
       "      <td>1.0</td>\n",
       "      <td>It&amp;#39;s rare to find a writer who combines Al...</td>\n",
       "      <td>278212.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0688170528</td>\n",
       "      <td>39 rare find writer combin alic hoffman 39 gif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22571</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Wild animus is a search for the primordial, a ...</td>\n",
       "      <td>278373.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0971880107</td>\n",
       "      <td>wild animus search primordi test human foundat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22572</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Filled with unrelenting suspense and surprisin...</td>\n",
       "      <td>278431.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0446608262</td>\n",
       "      <td>fill unrel suspens surpris plot twist everi te...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22576</th>\n",
       "      <td>1.0</td>\n",
       "      <td>Don&amp;#39;t miss Little Altars Everywhere, the N...</td>\n",
       "      <td>278692.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0060976845</td>\n",
       "      <td>39 miss littl altar everywher new york time be...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17410 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       cluster                                            summary       uid  \\\n",
       "0          0.0  Five American expatriates living in Budapest i...      19.0   \n",
       "1          0.0  After a violent encounter with a homeless man,...      51.0   \n",
       "2          0.0  A collection of advice on how to live a happy ...      75.0   \n",
       "3          0.0  In charming, beautiful, and wealthy old-South ...     125.0   \n",
       "4          0.0  Sixteen years after her own son fell victim to...     178.0   \n",
       "...        ...                                                ...       ...   \n",
       "22568      1.0  Nina Reilly takes on the case of Jessie Potter...  278096.0   \n",
       "22569      1.0  It&#39;s rare to find a writer who combines Al...  278212.0   \n",
       "22571      1.0  Wild animus is a search for the primordial, a ...  278373.0   \n",
       "22572      1.0  Filled with unrelenting suspense and surprisin...  278431.0   \n",
       "22576      1.0  Don&#39;t miss Little Altars Everywhere, the N...  278692.0   \n",
       "\n",
       "       rating        isbn                                            Stemmed  \n",
       "0         7.0  0375759778  five american expatri live budapest earli 1990...  \n",
       "1         9.0  0440225701  violent encount homeless man talent corpor law...  \n",
       "2         5.0  1558531025               collect advic live happi reward life  \n",
       "3        10.0  0679429220  charm beauti wealthi old south savannah georgi...  \n",
       "4         6.0  0451410319  sixteen year son fell victim serial killer cri...  \n",
       "...       ...         ...                                                ...  \n",
       "22568     2.0  0440236053  nina reilli take case jessi potter desper youn...  \n",
       "22569     5.0  0688170528  39 rare find writer combin alic hoffman 39 gif...  \n",
       "22571     1.0  0971880107  wild animus search primordi test human foundat...  \n",
       "22572     2.0  0446608262  fill unrel suspens surpris plot twist everi te...  \n",
       "22576     3.0  0060976845  39 miss littl altar everywher new york time be...  \n",
       "\n",
       "[17410 rows x 6 columns]"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#SnowballStemer(trasnform the word to shorter word with the same root meaning)\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "#create new series('stemmed')\n",
    "new_df['Stemmed'] = new_df['removestopwords'].apply(lambda x: ' '.join([stemmer.stem(word) for word in str(x).split()]))\n",
    "new_df =new_df.drop(columns=['Clean'])\n",
    "new_df =new_df.drop(columns=['removestopwords'])\n",
    "\n",
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 181,   35, 3594, ...,    0,    0,    0],\n",
       "       [ 616,  139, 1183, ...,    0,    0,    0],\n",
       "       [  68,  833,   19, ...,    0,    0,    0],\n",
       "       ...,\n",
       "       [  40,   61,   22, ...,    0,    0,    0],\n",
       "       [ 375, 3155,  224, ...,    0,    0,    0],\n",
       "       [   1,  191,  251, ...,    0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 193,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "final_summaries = new_df['Stemmed'].copy()\n",
    "# Tokenize the summary texts\n",
    "# weight matrix of one embedding for each unique word in summary \n",
    "summaries = new_df[\"Stemmed\"].copy()\n",
    "\n",
    "# Tokenize the summary texts\n",
    "token = Tokenizer()\n",
    "token.fit_on_texts(summaries)\n",
    "#len of each unique word in summary \n",
    "vocab_size = len(token.word_index) + 1 \n",
    "texts = token.texts_to_sequences(summaries) # encode to integer each word \n",
    "texts = pad_sequences(texts, padding='post')\n",
    "texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "#sequence for each word\n",
    "embeddings_index = dict()\n",
    "f = open('glove.6B.100d.txt', encoding=\"utf8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded %s word vectors.' % len(embeddings_index))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.1383    ,  0.30316001, -0.11122   , ...,  0.10495   ,\n",
       "         0.11652   , -0.43040001],\n",
       "       [-0.26287001,  0.29894   , -0.77744001, ...,  0.20399   ,\n",
       "        -0.68527001,  0.22225   ],\n",
       "       ...,\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 0.        ,  0.        ,  0.        , ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "execution_count": 195,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a weight matrix of one embedding for each unique word in summary texts\n",
    "embedding_matrix = zeros((vocab_size, 100))\n",
    "for word, i in token.word_index.items():\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "embedding_matrix\n",
    "embedding_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21185     6.0\n",
       "16803     9.0\n",
       "12274     4.0\n",
       "1667      6.0\n",
       "16833     8.0\n",
       "         ... \n",
       "11308     5.0\n",
       "19599     2.0\n",
       "933       7.0\n",
       "4502     10.0\n",
       "14503     7.0\n",
       "Name: rating, Length: 5746, dtype: float64"
      ]
     },
     "execution_count": 196,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "textTrain, textTest, ratingTrain, ratingTest = train_test_split(texts, new_df['rating'], test_size=0.33)\n",
    "ratingTest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_20\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_20 (Embedding)    (None, 43, 100)           1648400   \n",
      "                                                                 \n",
      " flatten_19 (Flatten)        (None, 4300)              0         \n",
      "                                                                 \n",
      " dense_56 (Dense)            (None, 512)               2202112   \n",
      "                                                                 \n",
      " dense_57 (Dense)            (None, 256)               131328    \n",
      "                                                                 \n",
      " dense_58 (Dense)            (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_59 (Dense)            (None, 11)                1419      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,016,155\n",
      "Trainable params: 2,367,755\n",
      "Non-trainable params: 1,648,400\n",
      "_________________________________________________________________\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/spetz/.local/lib/python3.10/site-packages/keras/engine/data_adapter.py:1696: FutureWarning: The behavior of `series[i:j]` with an integer-dtype index is deprecated. In a future version, this will be treated as *label-based* indexing, consistent with e.g. `series[i]` lookups. To retain the old behavior, use `series.iloc[i:j]`. To get the future behavior, use `series.loc[i:j]`.\n",
      "  return t[start:end]\n",
      "/home/spetz/.local/lib/python3.10/site-packages/keras/backend.py:5585: UserWarning: \"`sparse_categorical_crossentropy` received `from_logits=True`, but the `output` argument was produced by a Softmax activation and thus does not represent logits. Was this intended?\n",
      "  output, from_logits = _get_logits(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "187/187 [==============================] - 2s 12ms/step - loss: 2.1312 - accuracy: 0.2173 - val_loss: 2.0982 - val_accuracy: 0.2195\n",
      "Epoch 2/100\n",
      "187/187 [==============================] - 2s 11ms/step - loss: 1.9280 - accuracy: 0.2875 - val_loss: 2.1443 - val_accuracy: 0.2336\n",
      "Epoch 3/100\n",
      "187/187 [==============================] - 2s 11ms/step - loss: 1.6403 - accuracy: 0.4142 - val_loss: 2.2376 - val_accuracy: 0.2079\n",
      "Epoch 4/100\n",
      "187/187 [==============================] - 2s 11ms/step - loss: 1.3147 - accuracy: 0.5383 - val_loss: 2.5616 - val_accuracy: 0.1865\n",
      "Epoch 5/100\n",
      "187/187 [==============================] - 2s 11ms/step - loss: 1.0880 - accuracy: 0.6044 - val_loss: 2.6843 - val_accuracy: 0.2040\n",
      "Epoch 6/100\n",
      "187/187 [==============================] - 2s 11ms/step - loss: 0.9460 - accuracy: 0.6206 - val_loss: 2.9509 - val_accuracy: 0.2087\n",
      "Epoch 7/100\n",
      "187/187 [==============================] - 2s 11ms/step - loss: 0.8577 - accuracy: 0.6281 - val_loss: 3.0843 - val_accuracy: 0.1942\n",
      "Epoch 8/100\n",
      "187/187 [==============================] - 2s 11ms/step - loss: 0.7979 - accuracy: 0.6319 - val_loss: 3.3721 - val_accuracy: 0.1980\n",
      "Epoch 9/100\n",
      "187/187 [==============================] - 2s 11ms/step - loss: 0.7525 - accuracy: 0.6395 - val_loss: 3.6380 - val_accuracy: 0.1920\n",
      "Epoch 10/100\n",
      "187/187 [==============================] - 2s 11ms/step - loss: 0.7324 - accuracy: 0.6455 - val_loss: 3.7119 - val_accuracy: 0.1852\n",
      "Epoch 11/100\n",
      "187/187 [==============================] - 2s 11ms/step - loss: 0.7130 - accuracy: 0.6475 - val_loss: 3.7250 - val_accuracy: 0.1903\n",
      "Epoch 12/100\n",
      "187/187 [==============================] - 2s 11ms/step - loss: 0.6927 - accuracy: 0.6537 - val_loss: 4.1811 - val_accuracy: 0.1933\n",
      "Epoch 13/100\n",
      "187/187 [==============================] - 2s 11ms/step - loss: 0.6908 - accuracy: 0.6543 - val_loss: 3.9521 - val_accuracy: 0.2045\n",
      "Epoch 14/100\n",
      "187/187 [==============================] - 2s 12ms/step - loss: 0.6837 - accuracy: 0.6537 - val_loss: 4.4246 - val_accuracy: 0.1770\n",
      "Epoch 15/100\n",
      "187/187 [==============================] - 2s 12ms/step - loss: 0.6803 - accuracy: 0.6601 - val_loss: 4.5783 - val_accuracy: 0.2002\n",
      "Epoch 16/100\n",
      "187/187 [==============================] - 2s 11ms/step - loss: 0.6790 - accuracy: 0.6613 - val_loss: 4.3294 - val_accuracy: 0.2045\n",
      "Epoch 17/100\n",
      "187/187 [==============================] - 2s 11ms/step - loss: 0.6738 - accuracy: 0.6639 - val_loss: 4.6873 - val_accuracy: 0.1950\n",
      "Epoch 18/100\n",
      "187/187 [==============================] - 2s 11ms/step - loss: 0.6732 - accuracy: 0.6646 - val_loss: 4.6722 - val_accuracy: 0.1835\n",
      "Epoch 19/100\n",
      "187/187 [==============================] - 2s 11ms/step - loss: 0.6724 - accuracy: 0.6645 - val_loss: 4.9912 - val_accuracy: 0.1770\n",
      "Epoch 20/100\n",
      "187/187 [==============================] - 2s 11ms/step - loss: 0.7185 - accuracy: 0.6564 - val_loss: 4.7309 - val_accuracy: 0.2006\n",
      "Epoch 21/100\n",
      "187/187 [==============================] - 2s 11ms/step - loss: 0.7347 - accuracy: 0.6562 - val_loss: 4.8910 - val_accuracy: 0.2027\n",
      "Epoch 22/100\n",
      "187/187 [==============================] - 2s 11ms/step - loss: 0.7131 - accuracy: 0.6602 - val_loss: 4.9102 - val_accuracy: 0.2049\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fdad0d15f00>"
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow import keras\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy # Loss function being used\n",
    "from sklearn.model_selection import train_test_split # Train-test split\n",
    "import tensorflow as tf\n",
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(input_dim=vocab_size, output_dim=100, weights=[embedding_matrix], input_length=texts.shape[1], trainable=False))\n",
    "model.add(keras.layers.Flatten())\n",
    "model.add(keras.layers.Dense(512, activation='relu'))\n",
    "model.add(keras.layers.Dense(256, activation='relu' ))\n",
    "model.add(keras.layers.Dense(128, activation='relu' ))\n",
    "model.add(keras.layers.Dense(11, activation='softmax'))\n",
    "\n",
    "model.summary()\n",
    "\n",
    "# In[19]:\n",
    "\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss=SparseCategoricalCrossentropy(from_logits = True), optimizer='adam', metrics=['accuracy'])\n",
    "# Fit the model\n",
    "model.fit(textTrain, ratingTrain, epochs=100, batch_size=50, validation_split = 0.2,\n",
    "          callbacks=[tf.keras.callbacks.EarlyStopping(monitor=\"loss\", patience=3)])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "180/180 [==============================] - 0s 884us/step - loss: 4.8563 - accuracy: 0.2057\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(textTest, ratingTest) # Get the loss and accuracy based on the tests\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cluster0-cluster1\n",
    "cluster0 = csv[csv['cluster'] ==0]\n",
    "cluster1=csv[csv['cluster'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster0_null = cluster0[cluster0['rating'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>summary</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7620</th>\n",
       "      <td>Provides an introduction to classical myths pl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7622</th>\n",
       "      <td>With accurate descriptions of the changes that...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7626</th>\n",
       "      <td>A horse in nineteenth-century England recounts...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7627</th>\n",
       "      <td>By taking Gabe under his wing and teaching him...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7628</th>\n",
       "      <td>As a series of grisly murders terrorizes the s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12596</th>\n",
       "      <td>Success in this area leads Sheridan to have Cu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12597</th>\n",
       "      <td>Presents a fictional portrait of the relations...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12599</th>\n",
       "      <td>Good Faith captures the seductions and illusio...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12603</th>\n",
       "      <td>A novel about the difference that one person c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12604</th>\n",
       "      <td>In this novel, comedy and pathos, adventure an...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2817 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 summary  rating\n",
       "7620   Provides an introduction to classical myths pl...       0\n",
       "7622   With accurate descriptions of the changes that...       0\n",
       "7626   A horse in nineteenth-century England recounts...       0\n",
       "7627   By taking Gabe under his wing and teaching him...       0\n",
       "7628   As a series of grisly murders terrorizes the s...       0\n",
       "...                                                  ...     ...\n",
       "12596  Success in this area leads Sheridan to have Cu...       0\n",
       "12597  Presents a fictional portrait of the relations...       0\n",
       "12599  Good Faith captures the seductions and illusio...       0\n",
       "12603  A novel about the difference that one person c...       0\n",
       "12604  In this novel, comedy and pathos, adventure an...       0\n",
       "\n",
       "[2817 rows x 2 columns]"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster0_null\n",
    "cluster0_null = cluster0_null[['summary' ,'rating']]\n",
    "cluster0_null\n",
    "x=texts[0]\n",
    "y = cluster0_null['rating']\n",
    "\n",
    "cluster0_null\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2817"
      ]
     },
     "execution_count": 204,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "# Tokenize the summary texts\n",
    "# weight matrix of one embedding for each unique word in summary \n",
    "summaries = cluster0_null[\"summary\"].copy()\n",
    "\n",
    "# Tokenize the summary texts\n",
    "token = Tokenizer()\n",
    "token.fit_on_texts(summaries)\n",
    "#len of each unique word in summary \n",
    "vocab_size = len(token.word_index) + 1 \n",
    "texts = token.texts_to_sequences(summaries) # encode to integer each word \n",
    "texts = pad_sequences(texts, padding='post')\n",
    "len(texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[206], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m model\u001b[39m.\u001b[39;49mpredict(texts,y)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/pandas/core/generic.py:1527\u001b[0m, in \u001b[0;36mNDFrame.__nonzero__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1525\u001b[0m \u001b[39m@final\u001b[39m\n\u001b[1;32m   1526\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__nonzero__\u001b[39m(\u001b[39mself\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NoReturn:\n\u001b[0;32m-> 1527\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\n\u001b[1;32m   1528\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mThe truth value of a \u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mtype\u001b[39m(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m is ambiguous. \u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1529\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mUse a.empty, a.bool(), a.item(), a.any() or a.all().\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m   1530\u001b[0m     )\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all()."
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
